{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(\".env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting movies 0 - 20 of 496\n",
      "Getting movies 20 - 40 of 496\n",
      "Getting movies 40 - 60 of 496\n",
      "Getting movies 60 - 80 of 496\n",
      "Getting movies 80 - 100 of 496\n",
      "Getting movies 100 - 120 of 496\n",
      "Getting movies 120 - 140 of 496\n",
      "Getting movies 140 - 160 of 496\n",
      "Getting movies 160 - 180 of 496\n",
      "Getting movies 180 - 200 of 496\n",
      "Getting movies 200 - 220 of 496\n",
      "Getting movies 220 - 240 of 496\n",
      "Getting movies 240 - 260 of 496\n",
      "Getting movies 260 - 280 of 496\n",
      "Getting movies 280 - 300 of 496\n",
      "Getting movies 300 - 320 of 496\n",
      "Getting movies 320 - 340 of 496\n",
      "Getting movies 340 - 360 of 496\n",
      "Getting movies 360 - 380 of 496\n",
      "Getting movies 380 - 400 of 496\n",
      "Getting movies 400 - 420 of 496\n",
      "Getting movies 420 - 440 of 496\n",
      "Getting movies 440 - 460 of 496\n",
      "Getting movies 460 - 480 of 496\n",
      "Getting movies 480 - 500 of 496\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import os \n",
    "\n",
    "URL = os.getenv(\"URL\") \n",
    "USER_ID = os.getenv(\"USER_ID\")\n",
    "API_KEY = os.getenv(\"API_KEY\")\n",
    "\n",
    "def get_amount() -> int: \n",
    "    \"\"\"\n",
    "    Gets the amount of Movie items in user access \n",
    "    \n",
    "    Returns integer amoutn \n",
    "    \"\"\"\n",
    "    res = requests.get(f'{URL}/emby/Users/{USER_ID}/Items?StartIndex=0&Limit=1&Recursive=true&IncludeItemTypes=Movie&api_key={API_KEY}&Filters=IsPlayed&Fields=Budget,Genres,Overview,People,Revenue,Studios,Taglines,ProviderIds')\n",
    "    res.raise_for_status()\n",
    "\n",
    "    return res.json().get(\"TotalRecordCount\")\n",
    "\n",
    "def get_chunk(start: int = 0, chunk: int = 20) -> list: \n",
    "    \"\"\"\n",
    "    Gets a chunk of movie information from Jellyfin\n",
    "    \n",
    "    Optional starting point and chunk size \n",
    "\n",
    "    Returns a List of dictionaries with movie info\n",
    "    \"\"\"\n",
    "    res = requests.get(f'{URL}/emby/Users/{USER_ID}/Items?StartIndex={start}&Limit={chunk}&Recursive=true&IncludeItemTypes=Movie&api_key={API_KEY}&Filters=IsPlayed&Fields=Budget,Genres,Overview,People,Revenue,Studios,Taglines,ProviderIds')\n",
    "    res.raise_for_status()\n",
    "\n",
    "    return res.json().get(\"Items\")\n",
    "\n",
    "all_movies = list() \n",
    "\n",
    "size = get_amount()\n",
    "start = 0 \n",
    "chunk = 20 \n",
    "\n",
    "while start < size: \n",
    "    print(f'Getting movies {start} - {start + chunk} of {size}')\n",
    "    all_movies.extend(get_chunk(start=start, chunk=chunk))\n",
    "    start += chunk "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns to keep\n",
    "columns_to_keep = [\n",
    "    \"Name\",\n",
    "    \"PremiereDate\",\n",
    "    \"CriticRating\",\n",
    "    \"OfficialRating\",\n",
    "    \"Overview\",\n",
    "    \"Taglines\",\n",
    "    \"Genres\",\n",
    "    \"CommunityRating\",\n",
    "    \"RunTimeTicks\",\n",
    "    \"ProductionYear\",\n",
    "    \"People\",\n",
    "    \"Studios\",\n",
    "    \"UserData\",\n",
    "]\n",
    "\n",
    "# Function to filter a single movie dictionary\n",
    "def filter_movie(movie):\n",
    "    filtered = {key: value for key, value in movie.items() if key in columns_to_keep}\n",
    "\n",
    "    # Filter nested People\n",
    "    if \"People\" in filtered:\n",
    "        filtered[\"People\"] = [\n",
    "            [person.get(\"Id\"), person.get(\"Type\")] for person in filtered[\"People\"]\n",
    "        ]\n",
    "\n",
    "    # Filter Studios (keep only 'Name')\n",
    "    if \"Studios\" in filtered:\n",
    "        filtered[\"Studios\"] = [studio[\"Id\"] for studio in filtered[\"Studios\"] if \"Name\" in studio]\n",
    "\n",
    "    # Filter UserData (keep only 'IsFavorite')\n",
    "    if \"UserData\" in filtered:\n",
    "        filtered[\"IsFavorite\"] = filtered[\"UserData\"].get(\"IsFavorite\")\n",
    "        del filtered[\"UserData\"]\n",
    "\n",
    "    if \"Taglines\" in filtered: \n",
    "        filtered[\"Taglines\"] = (\"\\n\").join(filtered[\"Taglines\"])\n",
    "    return filtered\n",
    "\n",
    "# Process all movies\n",
    "filtered_movies = [filter_movie(movie) for movie in all_movies]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   CriticRating  CommunityRating  RunTimeTicks  ProductionYear  IsFavorite  \\\n",
      "0          0.89         0.592312      0.462071        0.932584           0   \n",
      "1          0.13         0.261701      0.372514        0.820225           0   \n",
      "2          0.31         0.381398      0.529278        0.876404           1   \n",
      "3          0.97         0.701255      0.273291        0.505618           1   \n",
      "4          0.00         0.654850      0.473029        0.988764           0   \n",
      "\n",
      "   year  month  day  day_of_week  is_weekend  ...  \\\n",
      "0  2018     11    9            4           0  ...   \n",
      "1  2008      7    1            1           0  ...   \n",
      "2  2013      7    3            2           0  ...   \n",
      "3  1980      7    1            1           0  ...   \n",
      "4  2023      3   23            3           0  ...   \n",
      "\n",
      "   Studio_ff8fcbfc0a663a60072cbb254ef98b83  \\\n",
      "0                                        0   \n",
      "1                                        0   \n",
      "2                                        0   \n",
      "3                                        0   \n",
      "4                                        0   \n",
      "\n",
      "   Studio_ff966337d51b0e006da6e16df7cb7ca1  Actor_Count  Director_Count  \\\n",
      "0                                        0           15               2   \n",
      "1                                        0           15               1   \n",
      "2                                        1           15               1   \n",
      "3                                        0           15               3   \n",
      "4                                        0           15               2   \n",
      "\n",
      "   Writer_Count  Producer_Count  Role_Actor  Role_Director  Role_Producer  \\\n",
      "0             4               4          15              2              4   \n",
      "1             2               7          15              1              7   \n",
      "2             3               9          15              1              9   \n",
      "3             3               5          15              3              5   \n",
      "4             4               9          15              2              9   \n",
      "\n",
      "   Role_Writer  \n",
      "0            4  \n",
      "1            2  \n",
      "2            3  \n",
      "3            3  \n",
      "4            4  \n",
      "\n",
      "[5 rows x 835 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, MinMaxScaler, OneHotEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "df = pd.DataFrame(filtered_movies)\n",
    "\n",
    "\"\"\"\n",
    "Binary Encoding\n",
    "\"\"\"\n",
    "df['IsFavorite'] = df['IsFavorite'].astype(int)\n",
    "\n",
    "\"\"\"\n",
    "Date Encoding\n",
    "\"\"\"\n",
    "df[\"PremiereDate\"] = pd.to_datetime(df['PremiereDate'])\n",
    "\n",
    "df['year'] = df['PremiereDate'].dt.year\n",
    "df['month'] = df['PremiereDate'].dt.month\n",
    "df['day'] = df['PremiereDate'].dt.day\n",
    "df['day_of_week'] = df['PremiereDate'].dt.dayofweek\n",
    "df['is_weekend'] = (df['day_of_week'] >= 5).astype(int)\n",
    "df['quarter'] = df['PremiereDate'].dt.quarter\n",
    "df['week_of_year'] = df['PremiereDate'].dt.isocalendar().week\n",
    "df['day_of_year'] = df['PremiereDate'].dt.dayofyear\n",
    "\n",
    "df = df.drop(columns=['PremiereDate'])\n",
    "\n",
    "\"\"\"\n",
    "String TF-IDF Vectorization\n",
    "\"\"\"\n",
    "# Name\n",
    "tfidf_name = TfidfVectorizer(max_features=50, stop_words='english')\n",
    "name_tfidf = tfidf_name.fit_transform(df['Name'].fillna(\"\"))\n",
    "\n",
    "tfidf_name_columns = [f\"Name_TFIDF_{word}\" for word in tfidf_name.get_feature_names_out()]\n",
    "df_tfidf_name = pd.DataFrame(name_tfidf.toarray(), columns=tfidf_name_columns)\n",
    "df = pd.concat([df, df_tfidf_name], axis=1)\n",
    "df = df.drop(columns=['Name'])\n",
    "\n",
    "# Overview\n",
    "tfidf_overview = TfidfVectorizer(max_features=50, stop_words='english')\n",
    "overview_tfidf = tfidf_overview.fit_transform(df['Overview'].fillna(\"\"))\n",
    "\n",
    "tfidf_overview_columns = [f\"Overview_TFIDF_{word}\" for word in tfidf_overview.get_feature_names_out()]\n",
    "df_tfidf_overview = pd.DataFrame(overview_tfidf.toarray(), columns=tfidf_overview_columns)\n",
    "df = pd.concat([df, df_tfidf_overview], axis=1)\n",
    "df = df.drop(columns=['Overview'])\n",
    "\n",
    "# Taglines\n",
    "tfidf_taglines = TfidfVectorizer(max_features=20, stop_words='english')\n",
    "taglines_tfidf = tfidf_taglines.fit_transform(df['Taglines'].fillna(\"\"))\n",
    "\n",
    "tfidf_tagline_columns = [f\"Tagline_TFIDF_{word}\" for word in tfidf_taglines.get_feature_names_out()]\n",
    "df_tfidf_taglines = pd.DataFrame(taglines_tfidf.toarray(), columns=tfidf_tagline_columns)\n",
    "df = pd.concat([df, df_tfidf_taglines], axis=1)\n",
    "df = df.drop(columns=['Taglines'])\n",
    "\n",
    "\"\"\"\n",
    "One-Hot Encoding Labels\n",
    "\"\"\"\n",
    "# One-Hot Encode CommunityRating\n",
    "ohe = OneHotEncoder(sparse_output=False)\n",
    "ratings_encoded = ohe.fit_transform(df[['OfficialRating']])\n",
    "ratings_columns = [f\"OfficialRating_{cat}\" for cat in ohe.categories_[0]]\n",
    "df_ratings = pd.DataFrame(ratings_encoded, columns=ratings_columns)\n",
    "\n",
    "# Concatenate to main DataFrame\n",
    "df = pd.concat([df, df_ratings], axis=1)\n",
    "df = df.drop(columns=['OfficialRating'])\n",
    "\n",
    "# Genres\n",
    "mlb_genres = MultiLabelBinarizer()\n",
    "genres_encoded = mlb_genres.fit_transform(df['Genres'])\n",
    "\n",
    "genre_columns = [f\"Genre_{g}\" for g in mlb_genres.classes_]\n",
    "df_genres = pd.DataFrame(genres_encoded, columns=genre_columns)\n",
    "df = pd.concat([df, df_genres], axis=1)\n",
    "df = df.drop(columns=['Genres'])\n",
    "\n",
    "# Studios\n",
    "mlb_studios = MultiLabelBinarizer()\n",
    "studios_encoded = mlb_studios.fit_transform(df['Studios'])\n",
    "\n",
    "studio_columns = [f\"Studio_{s}\" for s in mlb_studios.classes_]\n",
    "df_studios = pd.DataFrame(studios_encoded, columns=studio_columns)\n",
    "df = pd.concat([df, df_studios], axis=1)\n",
    "df = df.drop(columns=['Studios'])\n",
    "\n",
    "\"\"\"\n",
    "People Features - Role-Based Aggregation\n",
    "\"\"\"\n",
    "from collections import Counter\n",
    "\n",
    "# Function to count roles in the People column\n",
    "def count_roles(people):\n",
    "    roles = [p[1] for p in people]\n",
    "    return dict(Counter(roles))\n",
    "\n",
    "# Apply role counting\n",
    "role_counts = df['People'].apply(count_roles)\n",
    "\n",
    "df['Actor_Count'] = role_counts.apply(lambda x: x.get('Actor', 0))\n",
    "df['Director_Count'] = role_counts.apply(lambda x: x.get('Director', 0))\n",
    "df['Writer_Count'] = role_counts.apply(lambda x: x.get('Writer', 0))\n",
    "df['Producer_Count'] = role_counts.apply(lambda x: x.get('Producer', 0))\n",
    "\n",
    "# One-Hot Encode Roles while retaining hashed IDs\n",
    "people_expanded = []\n",
    "\n",
    "for i, movie in df.iterrows():\n",
    "    for person_id, role in movie['People']:\n",
    "        people_expanded.append({'MovieIndex': i, 'PersonId': person_id, 'Role': role})\n",
    "\n",
    "people_df = pd.DataFrame(people_expanded)\n",
    "\n",
    "# One-hot encode the Role column\n",
    "people_df = pd.get_dummies(people_df, columns=['Role'], prefix='Role')\n",
    "\n",
    "# Aggregate by MovieIndex to count unique PersonIds per role\n",
    "role_columns = [col for col in people_df.columns if 'Role_' in col]\n",
    "people_counts = people_df.groupby('MovieIndex')[role_columns].sum()\n",
    "\n",
    "# Merge back to main dataframe\n",
    "df = df.join(people_counts)\n",
    "df = df.drop(columns=['People'])\n",
    "\n",
    "\"\"\"\n",
    "Numerical Normalization\n",
    "\"\"\"\n",
    "numerical_features = ['CriticRating', 'CommunityRating', 'RunTimeTicks', 'ProductionYear']\n",
    "\n",
    "# MinMaxScaler for numerical columns\n",
    "scaler = MinMaxScaler()\n",
    "df[numerical_features] = scaler.fit_transform(df[numerical_features])\n",
    "\n",
    "\"\"\"\n",
    "Final Clean-up\n",
    "\"\"\"\n",
    "# Fill any remaining NaNs with 0 (optional)\n",
    "df = df.fillna(0)\n",
    "\n",
    "# Final DataFrame\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Features and target\n",
    "X = df.drop(columns=['IsFavorite'])  # Drop target column\n",
    "y = df['IsFavorite']                # Target column\n",
    "\n",
    "# Ensure all NaNs are handled\n",
    "X = X.fillna(0)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Optional scaling for numerical features (Random Forest doesn't require scaling but good practice)\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.71\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.97      0.81        64\n",
      "           1       0.82      0.25      0.38        36\n",
      "\n",
      "    accuracy                           0.71       100\n",
      "   macro avg       0.76      0.61      0.60       100\n",
      "weighted avg       0.74      0.71      0.66       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Random Forest Classifier\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=100,     # Number of trees\n",
    "    max_depth=None,       # Allow trees to grow fully\n",
    "    random_state=42,\n",
    "    n_jobs=-1             # Use all processors for parallel training\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
